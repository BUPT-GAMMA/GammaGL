Cora:
  seed: 39788
  learning_rate: 0.0005
  num_hidden: 512
  num_proj_hidden: 512
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.4
  drop_edge_rate_2: 0.3
  drop_feature_rate_1: 0
  drop_feature_rate_2: 0
  tau: 0.7
  num_epochs: 500
  weight_decay: 0.00001
CiteSeer:
  seed: 38108
  learning_rate: 0.001
  num_hidden: 256
  num_proj_hidden: 256
  activation: 'prelu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.3
  drop_edge_rate_2: 0.1
  drop_feature_rate_1: 0
  drop_feature_rate_2: 0
  tau: 0.9
  num_epochs: 200
  weight_decay: 0.00001
PubMed:
  seed: 23344
  learning_rate: 0.001
  num_hidden: 512
  num_proj_hidden: 512
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.4
  drop_edge_rate_2: 0.1
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.7
  num_epochs: 1400
  weight_decay: 0.00001

BlogCatalog:
  learning_rate: 0.001
  num_hidden: 256
  num_proj_hidden: 256
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.4
  drop_edge_rate_2: 0.3
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.7
  num_epochs: 1000
  weight_decay: 0.00001

Flickr:
  learning_rate: 0.001
  num_hidden: 256
  num_proj_hidden: 256
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.4
  drop_edge_rate_2: 0.1
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.4
  num_epochs: 1000
  weight_decay: 0.00001

Computers:
  learning_rate: 0.01
  num_hidden: 128
  num_proj_hidden: 128
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.6
  drop_edge_rate_2: 0.4
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.2
  num_epochs: 2500
  weight_decay: 0.00001
Photo:
  learning_rate: 0.0005
  num_hidden: 256
  num_proj_hidden: 64
  activation: 'relu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.3
  drop_edge_rate_2: 0.5
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.2
  num_epochs: 1000
  weight_decay: 0.00001
WikiCS:
  learning_rate: 0.01
  num_hidden: 256
  num_proj_hidden: 256
  activation: 'prelu'
  base_model: 'GCNConv'
  num_layers: 2
  drop_edge_rate_1: 0.2
  drop_edge_rate_2: 0.3
  drop_feature_rate_1: 0.0
  drop_feature_rate_2: 0.0
  tau: 0.4
  num_epochs: 1500
  weight_decay: 0.00001